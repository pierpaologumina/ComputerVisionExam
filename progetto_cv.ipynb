{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRL9wq53guGz"
   },
   "source": [
    "# FACE BLURRING BASED ON AGE DETECTION\n",
    "Studente: Pierpaolo Gumina<br>\n",
    "Docente: Prof. Sebastiano Battiato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vuole proporre un algoritmo di classificazione in grado di riconoscere uno o\n",
    "più volti nella scena (face recognition), stimare l’età (age detection) e adottare\n",
    "tecniche di offuscamento (blurring) con lo scopo di anonimizzare i volti di\n",
    "individui minorenni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94Pmuo6CguG-"
   },
   "source": [
    "### Contenuto del progetto:\n",
    "- [Setup](#Setup)\n",
    "- [Basato su Immagini](#Age-Detection-on-Image)\n",
    "- [Basato su Video](#Age-Detection-on-Video)\n",
    "    - [Basato sull'utilizzo della Webcam](#Age-Detection-on-Live-Webcam-Video)\n",
    "    - [Basato su un file video locale](#Age-Detection-on-a-Video-File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ys6GZyhPguHA"
   },
   "outputs": [],
   "source": [
    "# Importazione di librerie utili\n",
    "from PIL import Image, ImageFilter\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGo2q2jLguHA"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "P2TWA9ZAguHB"
   },
   "outputs": [],
   "source": [
    "# Caricamento del modello di CNN pre-allenato per l'age classification, inoltre si inizializza una lista\n",
    "# contenente il range di età\n",
    "\n",
    "model = load_model(\"age_detect_cnn_model.h5\")\n",
    "age_ranges = ['1-2', '3-9', '10-20', '21-27', '28-45', '46-65', '66-116']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esistono vari algoritmi pronti all’uso che permettono di realizzare un sistema di\n",
    "face detection, in particolare per questo progetto è stato utilizzato l’algoritmo\n",
    "Haar cascades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2QOiMDmDguHD"
   },
   "outputs": [],
   "source": [
    "# Importazione dell'Haar Cascades classifier in formato XML.\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sRTa4MldguHG"
   },
   "outputs": [],
   "source": [
    "# Definizione di una funzione per restringere la regione del viso rilevata per una migliorare la previsione nel modello\n",
    "\n",
    "def shrink_face_roi(x, y, w, h, scale=0.9):\n",
    "    wh_multiplier = (1-scale)/2\n",
    "    x_new = int(x + (w * wh_multiplier))\n",
    "    y_new = int(y + (h * wh_multiplier))\n",
    "    w_new = int(w * scale)\n",
    "    h_new = int(h * scale)\n",
    "    return (x_new, y_new, w_new, h_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dtOmR4HeguHH"
   },
   "outputs": [],
   "source": [
    "# Definizione di una funzione per creare la sovrapposizione del testo dell'età prevista sull'immagine.\n",
    "\n",
    "def create_age_text(img, text, pct_text, x, y, w, h):\n",
    "\n",
    "    # Definizione del carattere, delle scale e lo spessore.\n",
    "    fontFace = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    text_scale = 1.2\n",
    "    yrsold_scale = 0.7\n",
    "    pct_text_scale = 0.65\n",
    "\n",
    "    # Ottenerimento della larghezza, altezza e baseline del testo dell'età.\n",
    "    (text_width, text_height), text_bsln = cv2.getTextSize(text, fontFace=fontFace, fontScale=text_scale, thickness=2)\n",
    "    (yrsold_width, yrsold_height), yrsold_bsln = cv2.getTextSize(\"years old\", fontFace=fontFace, fontScale=yrsold_scale, thickness=1)\n",
    "    (pct_text_width, pct_text_height), pct_text_bsln = cv2.getTextSize(pct_text, fontFace=fontFace, fontScale=pct_text_scale, thickness=1)\n",
    "\n",
    "    # Calcolo delle coordinate del punto centrale del rettangolo contenente il testo.\n",
    "    x_center = x + (w/2)\n",
    "    y_text_center = y + h + 20\n",
    "    y_yrsold_center = y + h + 48\n",
    "    y_pct_text_center = y + h + 75\n",
    "\n",
    "    # Calcolo delle coordinate dell'angolo in basso a sinistra del testo in base alla dimensione del testo e al punto centrale del rettangolo calcolato sopra.\n",
    "    x_text_org = int(round(x_center - (text_width / 2)))\n",
    "    y_text_org = int(round(y_text_center + (text_height / 2)))\n",
    "    x_yrsold_org = int(round(x_center - (yrsold_width / 2)))\n",
    "    y_yrsold_org = int(round(y_yrsold_center + (yrsold_height / 2)))\n",
    "    x_pct_text_org = int(round(x_center - (pct_text_width / 2)))\n",
    "    y_pct_text_org = int(round(y_pct_text_center + (pct_text_height / 2)))\n",
    "\n",
    "    face_age_background = cv2.rectangle(img, (x-1, y+h), (x+w+1, y+h+94), (0, 100, 0), cv2.FILLED)\n",
    "    face_age_text = cv2.putText(img, text, org=(x_text_org, y_text_org), fontFace=fontFace, fontScale=text_scale, thickness=2, color=(255, 255, 255), lineType=cv2.LINE_AA)\n",
    "    yrsold_text = cv2.putText(img, \"years old\", org=(x_yrsold_org, y_yrsold_org), fontFace=fontFace, fontScale=yrsold_scale, thickness=1, color=(255, 255, 255), lineType=cv2.LINE_AA)\n",
    "    pct_age_text = cv2.putText(img, pct_text, org=(x_pct_text_org, y_pct_text_org), fontFace=fontFace, fontScale=pct_text_scale, thickness=1, color=(255, 255, 255), lineType=cv2.LINE_AA)\n",
    "\n",
    "    return (face_age_background, face_age_text, yrsold_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymize_face_pixelate(image, blocks=3):\n",
    "    \n",
    "    # divide l'immagine di input in blocchi di dimensione NxN \n",
    "    (h, w) = image.shape[:2]\n",
    "    xSteps = np.linspace(0, w, blocks + 1, dtype=\"int\")\n",
    "    ySteps = np.linspace(0, h, blocks + 1, dtype=\"int\")\n",
    "    \n",
    "    # cicla su ciascun blocco in entranbe le direzioni x, y\n",
    "    for i in range(1, len(ySteps)):\n",
    "        for j in range(1, len(xSteps)):\n",
    "            startX = xSteps[j - 1]\n",
    "            startY = ySteps[i - 1]\n",
    "            endX = xSteps[j]\n",
    "            endY = ySteps[i]\n",
    "            roi = image[startY:endY, startX:endX]\n",
    "            (B, G, R) = [int(x) for x in cv2.mean(roi)[:3]]\n",
    "            cv2.rectangle(image, (startX, startY), (endX, endY),\n",
    "                (B, G, R), -1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymize_face_simple(image, factor=3.0):\n",
    "    # determinare automaticamente la dimensione del kernel di sfocatura in base \n",
    "    # alle dimensioni spaziali dell'immagine di input\n",
    "    (h, w) = image.shape[:2]\n",
    "    kW = int(w / factor)\n",
    "    kH = int(h / factor)\n",
    "    # questo assicura che la larghezza del kernel sia dispari\n",
    "    if kW % 2 == 0:\n",
    "        kW -= 1\n",
    "    # questo assicura che l'altezza del kernel sia dispari\n",
    "    if kH % 2 == 0:\n",
    "        kH -= 1\n",
    "    # applicare una sfocatura gaussiana all'immagine di ingresso utilizzando la\n",
    "    # dimensione del kernel calcolata precedentemente\n",
    "    return cv2.GaussianBlur(image, (kW, kH), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tp1mDhoaguHI"
   },
   "outputs": [],
   "source": [
    "# In questa cella si definisce una funzione per trovare i volti in un'immagine per poi \n",
    "# classificare ogni volto trovato nelle fasce d'età definite sopra e applicare un filtro di blurring l'addove necessario.\n",
    "\n",
    "def classify_age(img):\n",
    "\n",
    "    # Si fa una copia dell'immagine per la sovrapposizione delle età e \n",
    "    # un'altra copia in scala di grigi da passare al modello per la classificazione dell'età.\n",
    "    \n",
    "    img_copy = np.copy(img)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Rilevare le facce nell'immagine usando la face_cascade caricata precedentemente e \n",
    "    # memorizzare le loro coordinate in una lista.\n",
    "    faces = face_cascade.detectMultiScale(img_copy, scaleFactor=1.2, minNeighbors=6, minSize=(100, 100))\n",
    "\n",
    "    # Cicla per ciascun volto trovato\n",
    "    for i, (x, y, w, h) in enumerate(faces):\n",
    "\n",
    "        # Si disegna un rettangolo intorno alla faccia trovata.\n",
    "        face_rect = cv2.rectangle(img_copy, (x, y), (x+w, y+h), (0, 100, 0), thickness=2)\n",
    "        \n",
    "        # Predire l'età della volto usando il modello caricato precedentemente.\n",
    "        x2, y2, w2, h2 = shrink_face_roi(x, y, w, h)\n",
    "        prova=img[y2:y2+h2, x2:x2+w2]\n",
    "        face_roi = img_gray[y2:y2+h2, x2:x2+w2]\n",
    "        face_roi = cv2.resize(face_roi, (200, 200))  \n",
    "        face_roi = face_roi.reshape(-1, 200, 200, 1)\n",
    "        face_age = age_ranges[np.argmax(model.predict(face_roi))]\n",
    "        face_age_pct = f\"({round(np.max(model.predict(face_roi))*100, 2)}%)\"\n",
    "        \n",
    "        # Richiamare la funzione definita precedentemente per creare \n",
    "        # la sovrapposizione dell'età prevista sull'immagine.\n",
    "        face_age_background, face_age_text, yrsold_text = create_age_text(img_copy, face_age, face_age_pct, x, y, w, h)\n",
    "        # se il volto predetto è minorenne si applica il filtro di blurring\n",
    "        if(face_age in age_ranges[0:3]):\n",
    "            face=anonymize_face_simple(prova)\n",
    "            img_copy[y2:y2+h2, x2:x2+w2] = face\n",
    "    return img_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pxhPOa-mguHK"
   },
   "outputs": [],
   "source": [
    "# Difinizione di una funzione per restituire il percorso dell'immagine con il nuovo nome di file.\n",
    "def new_img_name(org_img_path):\n",
    "    img_path, img_name_ext = os.path.split(org_img_path)\n",
    "    img_name, img_ext = os.path.splitext(img_name_ext)\n",
    "\n",
    "    new_img_name_ext = img_name+\"_WITH_AGE\"+img_ext\n",
    "    new_img_path = os.path.join(img_path, new_img_name_ext)\n",
    "\n",
    "    return new_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mmf66x4dguHN"
   },
   "outputs": [],
   "source": [
    "# Difinizione di una funzione per restituire il percorso dell'immagine con il nuovo nome di file.\n",
    "def new_vid_name(org_vid_path):\n",
    "    vid_path, vid_name_ext = os.path.split(org_vid_path)\n",
    "    vid_name, vid_ext = os.path.splitext(vid_name_ext)\n",
    "    new_vid_name_ext = vid_name+\"_WITH_AGE\"+\".mp4\"\n",
    "    new_vid_path = os.path.join(vid_path, new_vid_name_ext)\n",
    "    return new_vid_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMoVtmq-guHO"
   },
   "source": [
    "## Basato su Immagini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 527,
     "status": "ok",
     "timestamp": 1625154523312,
     "user": {
      "displayName": "Pierpaolo G.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhSlF2liLWx5m_0pt4UkGbTInDgEdSL6yqr-Gr3=s64",
      "userId": "05339987234802193679"
     },
     "user_tz": -120
    },
    "id": "Lv3RUTW3guHQ"
   },
   "outputs": [],
   "source": [
    "# Percorso di salvataggio in locale dell'immagine\n",
    "\n",
    "my_image = \"./img_test/due.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "background_save": true,
     "output_embedded_package_id": "10Ibw7ywacNBxujLDNUu2zPTq5VCoPoCo"
    },
    "id": "yq5XCewmguHQ",
    "outputId": "a5cec577-93ec-4ce4-b159-2e508bb9493c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ./img_test\\due_WITH_AGE.jpg\n"
     ]
    }
   ],
   "source": [
    "# Prendere il file nella locazione della cella precedente e passarlo al classificatore\n",
    "\n",
    "img = cv2.imread(my_image)\n",
    "age_img = classify_age(img)\n",
    "\n",
    "try:\n",
    "    new_my_image = new_img_name(my_image)\n",
    "    cv2.imwrite(new_my_image, age_img)\n",
    "    print(f\"Saved to {new_my_image}\")\n",
    "except:\n",
    "    print(\"Error: Could not save image!\")\n",
    "\n",
    "cv2.imshow(\"Age Detection on Live Video\", age_img)\n",
    "cv2.waitKey(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSt1CyxZguHR"
   },
   "source": [
    "## Basato su video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KBvxcAmguHR"
   },
   "source": [
    "La detection basata su video:\n",
    "1. viene dato in input un video;\n",
    "2. viene utilizzata la webcam del pc, inferenza in modalità real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtOGKpzpguHR"
   },
   "source": [
    "### Basato sull'utilizzo della Webcam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sMi3MFaguHS"
   },
   "source": [
    "Per la rilevazione basata su webcam verrà aperta una nuova finiestra. Premere il tasto \"Q\" della tastiera per uscire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Jh4tjOIgguHS",
    "outputId": "8ddf50b4-be41-4c8e-8f14-5b5e2c4db841"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to Webcam_20210722121047_WITH_AGE.mp4\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if (cap.isOpened() == False): \n",
    "    print(\"Unable to read camera feed!\")\n",
    "\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "cur_time = datetime.fromtimestamp(time.time()).strftime('%Y%m%d%H%M%S')\n",
    "out = cv2.VideoWriter(f\"Webcam_{cur_time}_WITH_AGE.mp4\", fourcc, 18, (frame_width, frame_height))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "    # Per ogni fotogramma..\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret==True:\n",
    "        \n",
    "        # Si esegue il classificatore sul fotogramma catturato dalla webcam\n",
    "        age_img = classify_age(frame)\n",
    "        \n",
    "        # Salvataggio del fotogramma sul video in uscita usando l'oggetto VideoWriter definito precedentemente.\n",
    "        out.write(age_img)\n",
    "\n",
    "        # Visualizzazione del fotogramma con l'età rilevata.\n",
    "        cv2.imshow(\"Age Detection on Live Video\", age_img)\n",
    "        \n",
    "        # Premere il tasto \"Q\" per uscire\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "# Rilascio dell'ogetto VideoCapture e VideoWriter, e chiusura della finistra.\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"Saved to Webcam_{cur_time}_WITH_AGE.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5SkEkWxguHT"
   },
   "source": [
    "### Basato su un file video locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "4OoklydNguHU"
   },
   "outputs": [],
   "source": [
    "# Percorso del video\n",
    "\n",
    "my_video = \"./video_test/baby.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1SaFkdAtQMLbODRVU3ku8QJw7keNtsBEu"
    },
    "id": "wY0ZH8M1guHU",
    "outputId": "dfc9db83-be99-468a-bf0b-f44d886c4a48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ./video_test\\baby_WITH_AGE.mp4\n"
     ]
    }
   ],
   "source": [
    "my_video = \"./video_test/test.mp4\"\n",
    "cap = cv2.VideoCapture(my_video)\n",
    "\n",
    "# Controlla se il viedeo può essere aperto\n",
    "if (cap.isOpened() == False): \n",
    "    print(\"Unable to read video!\")\n",
    "\n",
    "# Ottenere la larghezza e l'altezza del fotogramma video.\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Definizione del codec e creazione di un oggetto VideoWriter per salvare il video in uscita nella stessa posizione.\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "new_my_video = new_vid_name(my_video)\n",
    "out = cv2.VideoWriter(new_my_video, fourcc, 18, (frame_width, frame_height))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "    # Per ogni frame..\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret==True:\n",
    "        \n",
    "        # ..si esegue il classificatore sul frame \n",
    "        age_img = classify_age(frame)\n",
    "        \n",
    "        out.write(age_img)\n",
    "        \n",
    "        cv2.imshow(\"video\",age_img)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"Saved to {new_my_video}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AGE_CLASSIFICATION_OF_FACES_offline.ipynb",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
